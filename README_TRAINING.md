# Инструкция по обучению модели Shap-E

В этом руководстве описано, как подготовить датасет и запустить обучение для модели Shap-E.

## Требования

Перед началом обучения убедитесь, что у вас установлены все необходимые зависимости:

```bash
pip install -e .
```

## Структура датасета

Для обучения модели Shap-E вам необходимо подготовить датасет в следующем формате:

### Для обучения текстовой модели (text300M)

```
dataset/
├── images/               # Рендеренные изображения 3D-объектов с разных ракурсов
│   ├── object1_view1.png
│   ├── object1_view2.png
│   └── ...
├── points/               # Облака точек в формате .npy
│   ├── object1.npy       # Формат: (N, 3) или (3, N), где N - количество точек
│   ├── object2.npy
│   └── ...
├── cameras/              # Параметры камер для каждого ракурса (опционально)
│   ├── object1_view1.json
│   ├── object1_view2.json
│   └── ...
└── captions.csv          # Текстовые описания для каждого объекта
    # Формат CSV: object_id,caption
    # например: object1,"красная ваза с узорами"
```

### Для обучения модели на основе изображений (image300M)

```
dataset/
├── images/               # Рендеренные изображения 3D-объектов с разных ракурсов
│   ├── object1_view1.png
│   ├── object1_view2.png
│   └── ...
├── points/               # Облака точек в формате .npy
│   ├── object1.npy       # Формат: (N, 3) или (3, N), где N - количество точек
│   ├── object2.npy
│   └── ...
└── metadata.json         # Метаданные, связывающие изображения с облаками точек
```

## Подготовка датасета

### 1. Рендеринг 3D-моделей

Для создания рендеров с разных ракурсов вы можете использовать Blender или другие 3D-программы. Рекомендуется создать 60 ракурсов для каждого объекта.

### 2. Генерация облаков точек

Облака точек можно генерировать из 3D-моделей с помощью различных инструментов. Рекомендуемое количество точек - 16,384.

### 3. Подготовка текстовых описаний

Для текстово-условной модели (text300M) подготовьте текстовые описания для каждого объекта.

## Запуск обучения

Для запуска обучения используйте скрипт `train.py`:

### Обучение текстовой модели

```bash
python train.py --data_dir path/to/dataset --output_dir output/text_model --model_type text300M --batch_size 4 --epochs 10 --lr 1e-5
```

### Обучение модели на основе изображений

```bash
python train.py --data_dir path/to/dataset --output_dir output/image_model --model_type image300M --batch_size 4 --epochs 10 --lr 1e-5
```

### Дополнительные параметры

- `--data_dir`: Путь к директории с датасетом (обязательный параметр)
- `--output_dir`: Директория для сохранения результатов (по умолчанию: "output")
- `--model_type`: Тип модели ("text300M" или "image300M") (по умолчанию: "text300M")
- `--batch_size`: Размер батча (по умолчанию: 4)
- `--epochs`: Количество эпох (по умолчанию: 10)
- `--lr`: Скорость обучения (по умолчанию: 1e-5)
- `--device`: Устройство для обучения ("cuda" или "cpu") (по умолчанию: "cuda" если доступно, иначе "cpu")
- `--config`: Путь к пользовательскому конфигурационному файлу (опционально)

## Настройка датасета

Для адаптации скрипта под ваш датасет, вам необходимо модифицировать функцию `load_dataset` в файле `train.py`. Замените класс `DummyDataset` своей реализацией, которая будет правильно загружать ваши данные.

## Настройка параметров диффузии

Если вам нужно изменить параметры диффузии, создайте свой конфигурационный файл на основе стандартного и передайте его с помощью параметра `--config`.

## Рекомендации по обучению

1. Начните с небольшого датасета для тестирования процесса обучения
2. Используйте GPU для значительного ускорения обучения
3. Мониторьте потери и при необходимости корректируйте скорость обучения
4. Сохраняйте промежуточные чекпоинты, чтобы иметь возможность возобновить обучение

## Проблемы и решения

### Ошибка памяти GPU

Если возникает ошибка нехватки памяти GPU, попробуйте уменьшить `batch_size` или использовать модель с меньшим количеством параметров.

### Медленное обучение на CPU

Обучение на CPU может быть очень медленным. Рекомендуется использовать GPU. 