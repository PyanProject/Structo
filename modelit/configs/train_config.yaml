# General settings
experiment_name: "text_to_3d_modelnet40_optimized"
seed: 42
device: "cuda"
log_dir: "logs"
checkpoint_dir: "checkpoints"

# Data parameters
data:
  dataset_name: "ModelNet40"
  dataset_path: "data/ModelNet40"
  train_split: 0.8
  validation_split: 0.1
  test_split: 0.1
  batch_size: 2
  num_workers: 2
  voxel_resolution: 20
  text_max_length: 77
  augmentation: True
  pin_memory: False

# Model parameters
model:
  text_encoder:
    type: "CLIP"
    pretrained: True
    freeze: True
    embedding_dim: 256
  
  shape_generator:
    type: "VoxelTransformer"
    latent_dim: 256
    hidden_dims: [256, 128, 64, 32, 16]
    dropout: 0.2
    num_heads: 4
    num_layers: 2
    voxel_dim: 20

# Training parameters
training:
  num_epochs: 5
  learning_rate: 0.0001
  weight_decay: 0.0001
  lr_scheduler:
    type: "cosine"
    warmup_epochs: 5
  use_mixed_precision: True
  clip_grad_norm: 1.0
  save_interval: 5
  evaluate_interval: 2
  early_stopping:
    patience: 10
    min_delta: 0.001
  accumulation_steps: 8

# Loss parameters
loss:
  bce_weight: 1.0
  l1_weight: 0.1

# Evaluation metrics
evaluation:
  metrics: ["chamfer_distance", "iou", "f_score"]
  visualization:
    num_samples: 3
    output_dir: "visualizations"

# Logging
logging:
  wandb:
    use: False
    project: "text_to_3d"
    entity: "your_entity"
  tensorboard:
    use: True
  memory_tracking: True

# Optimization
optimization:
  empty_cache_frequency: "batch"
  optimize_memory: True
  gradient_checkpointing: True 